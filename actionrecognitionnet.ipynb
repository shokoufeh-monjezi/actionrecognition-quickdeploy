{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Action recognition using TAO ActionRecognitionNet\n",
    "\n",
    "Transfer learning is the process of transferring learned features from one application to another. It is a commonly used training technique where you use a model trained on one task and re-train to use it on a different task. \n",
    "\n",
    "Train Adapt Optimize (TAO) Toolkit  is a simple and easy-to-use Python based AI toolkit for taking purpose-built AI models and customizing them with users' own data.\n",
    "\n",
    "<img align=\"center\" src=\"https://developer.nvidia.com/sites/default/files/akamai/embedded-transfer-learning-toolkit-software-stack-1200x670px.png\" width=\"1080\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "In this notebook, you will learn how to leverage the simplicity and convenience of TAO to:\n",
    "\n",
    "* Train 3D RGB only for action recognition on the subset of [HMDB51](https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/) dataset.\n",
    "* Evaluate the trained model.\n",
    "* Run Inference on the trained model.\n",
    "* Export the trained model to a .etlt file for deployment to DeepStream.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "This notebook shows an example usecase of ActionRecognitionNet using Train Adapt Optimize (TAO) Toolkit.\n",
    "\n",
    "1. [Set up env variables and map drives](#head-0)\n",
    "2. [Installing the TAO launcher](#head-1)\n",
    "3. [Prepare dataset and pre-trained model](#head-2)\n",
    "4. [Provide training specification](#head-3)\n",
    "5. [Run TAO training](#head-4)\n",
    "6. [Evaluate trained models](#head-5)\n",
    "7. [Inferences](#head-6)\n",
    "8. [Deploy](#head-7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up env variables and map drives <a class=\"anchor\" id=\"head-0\"></a>\n",
    "\n",
    "When using the purpose-built pretrained models from NGC, please make sure to set the `$KEY` environment variable to the key as mentioned in the model overview. Failing to do so, can lead to errors when trying to load them as pretrained models.\n",
    "FIX THE PATH:\n",
    "please edit env variables based on the path to specs, data and results folder in your system. In this example \"/home/jupyter/action_recognition_net\" shows the path to the folder including jupyter notebook and specs file and we will create data and results folder in the same folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HOST_DATA_DIR=/home/jupyter/action_recognition_net/data\n",
      "env: HOST_SPECS_DIR=/home/jupyter/action_recognition_net/specs\n",
      "env: HOST_RESULTS_DIR=/home/jupyter/action_recognition_net/results\n",
      "env: KEY=nvidia_tao\n"
     ]
    }
   ],
   "source": [
    "%env HOST_DATA_DIR=/home/jupyter/action_recognition_net/data\n",
    "# note: You could set the HOST_SPECS_DIR to folder of the experiments specs downloaded with the notebook\n",
    "%env HOST_SPECS_DIR=/home/jupyter/action_recognition_net/specs\n",
    "%env HOST_RESULTS_DIR=/home/jupyter/action_recognition_net/results\n",
    "\n",
    "# Set your encryption key, and use the same key for all commands\n",
    "%env KEY = nvidia_tao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p $HOST_DATA_DIR\n",
    "! mkdir -p $HOST_SPECS_DIR\n",
    "! mkdir -p $HOST_RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset and pre-trained model <a class=\"anchor\" id=\"head-2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Prepare dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We will be using the [HMDB51](https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/) dataset for the tutorial. Download the HMDB51 dataset and unzip them firstly (We choose fall_floor/ride_bike for this tutorial): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-10 23:04:57--  https://github.com/shokoufeh-monjezi/TAOData/releases/download/v1.0/hmdb51_org.zip\n",
      "Resolving github.com (github.com)... 140.82.112.4\n",
      "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/490854586/606f6396-a03c-4b1d-9749-3983bd0da295?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220510T230457Z&X-Amz-Expires=300&X-Amz-Signature=ebcbdd373c335a93dbc5c99cb03057e9f6d2b40487bbc1489aca045eeca45d97&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=490854586&response-content-disposition=attachment%3B%20filename%3Dhmdb51_org.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-05-10 23:04:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/490854586/606f6396-a03c-4b1d-9749-3983bd0da295?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220510T230457Z&X-Amz-Expires=300&X-Amz-Signature=ebcbdd373c335a93dbc5c99cb03057e9f6d2b40487bbc1489aca045eeca45d97&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=490854586&response-content-disposition=attachment%3B%20filename%3Dhmdb51_org.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 70362618 (67M) [application/octet-stream]\n",
      "Saving to: ‘/home/jupyter/action_recognition_net/data/hmdb51_org.zip’\n",
      "\n",
      "hmdb51_org.zip      100%[===================>]  67.10M  99.7MB/s    in 0.7s    \n",
      "\n",
      "2022-05-10 23:04:58 (99.7 MB/s) - ‘/home/jupyter/action_recognition_net/data/hmdb51_org.zip’ saved [70362618/70362618]\n",
      "\n",
      "Archive:  /home/jupyter/action_recognition_net/data/hmdb51_org.zip\n",
      "  inflating: /home/jupyter/action_recognition_net/data/videos/hmdb51_org/fall_floor.zip  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/videos/hmdb51_org/ride_bike.zip  \n",
      "Archive:  /home/jupyter/action_recognition_net/data/videos/hmdb51_org/fall_floor.zip\n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/20060723sfjfffightcoldplay_fall_floor_f_cm_np1_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/50_FIRST_DATES_fall_floor_f_cm_np1_fr_med_14.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/American_History_X_fall_floor_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/American_History_X_fall_floor_f_cm_np1_le_bad_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/American_History_X_fall_floor_f_nm_np1_ba_bad_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/APOCALYPTO_fall_floor_f_nm_np1_ba_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BATMAN_BEGINS_fall_floor_f_cm_np1_ba_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BATMAN_BEGINS_fall_floor_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BATMAN_BEGINS_fall_floor_f_cm_np1_ba_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BATMAN_BEGINS_fall_floor_h_cm_np1_fr_bad_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BIG_FISH_fall_floor_f_cm_np1_fr_med_24.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BIG_FISH_fall_floor_f_nm_np1_fr_bad_21.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BIG_FISH_fall_floor_f_nm_np1_fr_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BIG_FISH_fall_floor_f_nm_np1_fr_med_26.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BLACK_HAWK_DOWN_fall_floor_f_cm_np1_fr_bad_34.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BLACK_HAWK_DOWN_fall_floor_f_cm_np1_ri_med_13.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/BLACK_HAWK_DOWN_fall_floor_u_cm_np1_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Blade_Vs_Deacon_Frost_Sword_Fight_Scene_fall_floor_f_cm_np2_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/CasinoRoyale_fall_floor_f_cm_np1_fr_med_7.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/CastAway1_fall_floor_u_nm_np1_fr_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Catch_Me_If_You_Can_fall_floor_f_cm_np1_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Crash_fall_floor_u_cm_np1_fr_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/EVOLUTION_fall_floor_f_cm_np1_fr_med_21.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/EVOLUTION_fall_floor_f_nm_np1_ba_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_3_fall_floor_f_nm_np1_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_4_fall_floor_u_cm_np1_fr_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_5_fall_floor_u_cm_np1_fr_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_6_fall_floor_f_nm_np1_fr_med_9.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_7_fall_floor_f_cm_np1_ba_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Fellowship_7_fall_floor_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Finding_Forrester_3_fall_floor_f_cm_np2_ri_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Glory_fall_floor_f_cm_np1_ba_med_46.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Glory_fall_floor_f_cm_np1_fr_med_39.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Glory_fall_floor_u_cm_np1_fr_med_55.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/HP_PRISONER_OF_AZKABAN_fall_floor_f_cm_np1_ri_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/HP_PRISONER_OF_AZKABAN_fall_floor_u_cm_np1_fr_med_14.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_bad_20.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_bad_21.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_bad_33.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_bad_49.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_med_35.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ba_med_50.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_fr_bad_22.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_fr_bad_36.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_fr_bad_47.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_fr_med_40.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_le_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_le_med_41.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_cm_np1_ri_med_19.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_nm_np1_ba_bad_23.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_nm_np1_ba_bad_54.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_nm_np1_le_bad_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_f_nm_np1_le_med_13.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_u_cm_np1_fr_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/KUNG_FU_HUSTLE_fall_floor_u_nm_np1_le_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_ba_med_13.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_fr_med_19.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_fr_med_25.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_le_bad_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_le_med_12.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_le_med_17.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_f_cm_np1_le_med_31.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/LONGESTYARD_fall_floor_h_nm_np1_fr_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/MeettheFockers_fall_floor_f_nm_np1_fr_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/MeettheFockers_fall_floor_f_nm_np1_fr_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/OldSchool_fall_floor_f_cm_np1_ri_med_17.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Pirates_6_fall_floor_f_cm_np1_fr_bad_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Pirates_7_fall_floor_f_nm_np3_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Prelinger_ActYourA1949_fall_floor_f_cm_np1_ri_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Prelinger_ActYourA1949_fall_floor_f_nm_np1_ri_med_9.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RATRACE_fall_floor_f_cm_np1_fr_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RATRACE_fall_floor_u_cm_np1_fr_bad_23.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Return_of_the_King_1_fall_floor_u_nm_np1_le_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Return_of_the_King_4_fall_floor_u_cm_np1_fr_med_9.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Return_of_the_King_8_fall_floor_f_cm_np1_ba_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_cm_np1_ba_bad_36.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_cm_np1_ba_med_51.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_cm_np1_fr_bad_30.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_cm_np1_fr_med_33.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_cm_np1_fr_med_39.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_f_nm_np1_fr_med_49.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_l_cm_np1_ba_med_44.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_u_cm_np1_fr_med_37.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_u_cm_np2_fr_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RETURN_OF_THE_KING_fall_floor_u_nm_np2_ba_med_35.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/RushHour2_fall_floor_f_cm_np1_fr_bad_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Superbad_fall_floor_u_nm_np1_ba_bad_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/SweeneyTodd_fall_floor_u_nm_np1_fr_bad_12.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/The_Matrix_3_fall_floor_f_cm_np1_ba_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/The_Matrix_5_fall_floor_f_nm_np1_fr_bad_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/The_Matrix_6_fall_floor_f_nm_np1_ba_bad_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/The_Matrix_Revolutions_6_fall_floor_f_cm_np1_fr_bad_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/The_Matrix_Revolutions_6_fall_floor_u_cm_np1_fr_bad_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_ba_bad_31.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_ba_bad_87.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_ba_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_ba_med_85.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_fr_bad_41.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_fr_med_33.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_fr_med_36.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_fr_med_55.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_fr_med_89.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_le_med_75.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_le_med_98.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_cm_np1_ri_bad_73.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_ba_bad_20.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_ba_bad_65.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_ba_bad_74.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_ba_bad_94.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_bad_100.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_bad_93.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_goo_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_med_18.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_med_61.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_fr_med_84.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_le_bad_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_le_bad_67.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_f_nm_np1_ri_bad_92.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_u_cm_np1_ba_med_86.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/THE_PROTECTOR_fall_floor_u_cm_np1_fr_med_56.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_f_nm_np1_ba_bad_40.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_f_nm_np1_fr_med_65.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_f_nm_np2_ba_bad_66.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_h_cm_np1_ri_bad_117.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_cm_np1_ba_bad_82.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_cm_np1_fr_med_108.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_cm_np1_fr_med_62.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_cm_np1_fr_med_63.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_nm_np1_ba_med_97.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_nm_np1_fr_med_70.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheBoondockSaints_fall_floor_u_nm_np2_fr_med_64.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheLastManOnearth_fall_floor_f_cm_np1_fr_med_58.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/TheLittleShopofHorrors_fall_floor_u_cm_np1_ri_med_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Two_Towers_3_fall_floor_u_cm_np1_fr_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Veoh_Alpha_Dog_1_fall_floor_f_cm_np1_fr_med_35.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/fall_floor/Veoh_Alpha_Dog_1_fall_floor_u_cm_np1_fr_med_46.avi  \n",
      "Archive:  /home/jupyter/action_recognition_net/data/videos/hmdb51_org/ride_bike.zip\n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_fr_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_fr_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_fr_med_7.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_le_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ri_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ri_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Bicycle_Tips_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Bicycle_Tips_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Bicycle_Tips_ride_bike_f_cm_np1_ri_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ba_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ri_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ri_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_Eigenbau_ride_bike_f_cm_np1_le_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_Eigenbau_ride_bike_f_cm_np1_ri_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_ride_bike_f_cm_np2_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_ride_bike_f_cm_np2_le_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_fahren_ride_bike_f_cm_np2_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Fahrrad_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Finding_Forrester_4_ride_bike_f_cm_np1_fr_bad_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Finding_Forrester_5_ride_bike_f_cm_np1_fr_bad_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Finding_Forrester_5_ride_bike_f_cm_np1_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/I_want_to_ride_my_bicycle_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Justin_lernt_Fahrrad_fahren_ride_bike_f_cm_np1_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Justin_lernt_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Justin_lernt_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_7.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_nm_np1_fr_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_l_cm_np1_le_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_l_cm_np1_le_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/lady_on_bike_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/lady_on_bike_ride_bike_f_cm_np1_ri_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_7.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_9.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_12.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_13.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_7.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_fr_med_10.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_bad_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ba_med_11.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_fr_med_15.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_14.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_16.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ri_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ri_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ri_med_6.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_l_cm_np1_ba_med_8.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_l_cm_np1_ba_med_9.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_l_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np2_fr_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np2_fr_med_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_bad_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_4.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_5.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ri_bad_1.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_fr_med_3.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_0.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2.avi  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/raw_data/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_1.avi  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "!wget -P $HOST_DATA_DIR \"https://github.com/shokoufeh-monjezi/TAOData/releases/download/v1.0/hmdb51_org.zip\"\n",
    "!mkdir -p $HOST_DATA_DIR/videos && unzip  $HOST_DATA_DIR/hmdb51_org.zip -d $HOST_DATA_DIR/videos\n",
    "!mkdir -p $HOST_DATA_DIR/raw_data\n",
    "!unzip $HOST_DATA_DIR/videos/hmdb51_org/fall_floor.zip -d $HOST_DATA_DIR/raw_data\n",
    "!unzip $HOST_DATA_DIR/videos/hmdb51_org/ride_bike.zip -d $HOST_DATA_DIR/raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the dataset process script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tao_toolkit_recipes'...\n",
      "remote: Enumerating objects: 109, done.\u001b[K\n",
      "remote: Counting objects: 100% (109/109), done.\u001b[K\n",
      "remote: Compressing objects: 100% (79/79), done.\u001b[K\n",
      "remote: Total 109 (delta 42), reused 85 (delta 21), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (109/109), 194.27 KiB | 2.11 MiB/s, done.\n",
      "Resolving deltas: 100% (42/42), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/NVIDIA-AI-IOT/tao_toolkit_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the dependency for data generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting xmltodict\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.8/site-packages (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.8/site-packages (from opencv-python) (1.20.3)\n",
      "Installing collected packages: xmltodict\n",
      "Successfully installed xmltodict-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install xmltodict opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the process script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/action_recognition_net/data/raw_data\n",
      "/home/jupyter/action_recognition_net/data/processed_data\n",
      "Preprocess fall_floor\n",
      "f cnt: 55.0\n",
      "f cnt: 51.0\n",
      "f cnt: 64.0\n",
      "f cnt: 34.0\n",
      "f cnt: 110.0\n",
      "f cnt: 63.0\n",
      "f cnt: 72.0\n",
      "f cnt: 49.0\n",
      "f cnt: 48.0\n",
      "f cnt: 74.0\n",
      "f cnt: 72.0\n",
      "f cnt: 47.0\n",
      "f cnt: 72.0\n",
      "f cnt: 79.0\n",
      "f cnt: 47.0\n",
      "f cnt: 55.0\n",
      "f cnt: 77.0\n",
      "f cnt: 60.0\n",
      "f cnt: 79.0\n",
      "f cnt: 57.0\n",
      "f cnt: 79.0\n",
      "f cnt: 49.0\n",
      "f cnt: 50.0\n",
      "f cnt: 48.0\n",
      "f cnt: 59.0\n",
      "f cnt: 86.0\n",
      "f cnt: 50.0\n",
      "f cnt: 43.0\n",
      "f cnt: 49.0\n",
      "f cnt: 46.0\n",
      "f cnt: 79.0\n",
      "f cnt: 54.0\n",
      "f cnt: 63.0\n",
      "f cnt: 148.0\n",
      "f cnt: 49.0\n",
      "f cnt: 50.0\n",
      "f cnt: 73.0\n",
      "f cnt: 54.0\n",
      "f cnt: 48.0\n",
      "f cnt: 50.0\n",
      "f cnt: 48.0\n",
      "f cnt: 74.0\n",
      "f cnt: 50.0\n",
      "f cnt: 74.0\n",
      "f cnt: 45.0\n",
      "f cnt: 47.0\n",
      "f cnt: 78.0\n",
      "f cnt: 48.0\n",
      "f cnt: 51.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 55.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 51.0\n",
      "f cnt: 49.0\n",
      "f cnt: 51.0\n",
      "f cnt: 78.0\n",
      "f cnt: 50.0\n",
      "f cnt: 48.0\n",
      "f cnt: 47.0\n",
      "f cnt: 56.0\n",
      "f cnt: 76.0\n",
      "f cnt: 79.0\n",
      "f cnt: 56.0\n",
      "f cnt: 49.0\n",
      "f cnt: 44.0\n",
      "f cnt: 58.0\n",
      "f cnt: 78.0\n",
      "f cnt: 80.0\n",
      "f cnt: 53.0\n",
      "f cnt: 47.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 73.0\n",
      "f cnt: 26.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 45.0\n",
      "f cnt: 50.0\n",
      "f cnt: 45.0\n",
      "f cnt: 43.0\n",
      "f cnt: 89.0\n",
      "f cnt: 39.0\n",
      "f cnt: 78.0\n",
      "f cnt: 55.0\n",
      "f cnt: 48.0\n",
      "f cnt: 47.0\n",
      "f cnt: 50.0\n",
      "f cnt: 43.0\n",
      "f cnt: 49.0\n",
      "f cnt: 48.0\n",
      "f cnt: 47.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 47.0\n",
      "f cnt: 78.0\n",
      "f cnt: 50.0\n",
      "f cnt: 50.0\n",
      "f cnt: 79.0\n",
      "f cnt: 49.0\n",
      "f cnt: 49.0\n",
      "f cnt: 138.0\n",
      "f cnt: 47.0\n",
      "f cnt: 48.0\n",
      "f cnt: 83.0\n",
      "f cnt: 84.0\n",
      "f cnt: 48.0\n",
      "f cnt: 23.0\n",
      "f cnt: 47.0\n",
      "f cnt: 49.0\n",
      "f cnt: 50.0\n",
      "f cnt: 45.0\n",
      "f cnt: 48.0\n",
      "f cnt: 44.0\n",
      "f cnt: 47.0\n",
      "f cnt: 75.0\n",
      "f cnt: 49.0\n",
      "f cnt: 53.0\n",
      "f cnt: 45.0\n",
      "f cnt: 49.0\n",
      "f cnt: 50.0\n",
      "f cnt: 49.0\n",
      "f cnt: 45.0\n",
      "f cnt: 78.0\n",
      "f cnt: 54.0\n",
      "f cnt: 49.0\n",
      "f cnt: 51.0\n",
      "f cnt: 56.0\n",
      "f cnt: 69.0\n",
      "f cnt: 45.0\n",
      "f cnt: 87.0\n",
      "f cnt: 74.0\n",
      "f cnt: 60.0\n",
      "Preprocess ride_bike\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 116.0\n",
      "f cnt: 246.0\n",
      "f cnt: 169.0\n",
      "f cnt: 125.0\n",
      "f cnt: 180.0\n",
      "f cnt: 81.0\n",
      "f cnt: 62.0\n",
      "f cnt: 119.0\n",
      "f cnt: 124.0\n",
      "f cnt: 79.0\n",
      "f cnt: 85.0\n",
      "f cnt: 79.0\n",
      "f cnt: 79.0\n",
      "f cnt: 87.0\n",
      "f cnt: 120.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 75.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 110.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 92.0\n",
      "f cnt: 136.0\n",
      "f cnt: 140.0\n",
      "f cnt: 159.0\n",
      "f cnt: 153.0\n",
      "f cnt: 105.0\n",
      "f cnt: 141.0\n",
      "f cnt: 144.0\n",
      "f cnt: 156.0\n",
      "f cnt: 137.0\n",
      "f cnt: 80.0\n",
      "f cnt: 193.0\n",
      "f cnt: 167.0\n",
      "f cnt: 93.0\n",
      "f cnt: 120.0\n",
      "f cnt: 82.0\n",
      "f cnt: 82.0\n",
      "f cnt: 100.0\n",
      "f cnt: 54.0\n",
      "f cnt: 68.0\n",
      "f cnt: 55.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 128.0\n",
      "f cnt: 38.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 79.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 79.0\n",
      "f cnt: 80.0\n",
      "f cnt: 113.0\n",
      "f cnt: 80.0\n",
      "f cnt: 79.0\n",
      "f cnt: 79.0\n",
      "f cnt: 79.0\n",
      "f cnt: 80.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 94.0\n",
      "f cnt: 81.0\n",
      "f cnt: 51.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 93.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 82.0\n",
      "f cnt: 81.0\n",
      "f cnt: 135.0\n",
      "f cnt: 81.0\n",
      "f cnt: 82.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 81.0\n",
      "f cnt: 108.0\n",
      "f cnt: 146.0\n",
      "f cnt: 84.0\n",
      "f cnt: 80.0\n",
      "f cnt: 74.0\n",
      "f cnt: 108.0\n",
      "f cnt: 55.0\n",
      "f cnt: 80.0\n",
      "f cnt: 117.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n",
      "f cnt: 95.0\n",
      "f cnt: 107.0\n",
      "f cnt: 85.0\n",
      "f cnt: 117.0\n",
      "f cnt: 80.0\n",
      "f cnt: 80.0\n"
     ]
    }
   ],
   "source": [
    "!cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && bash ./preprocess_HMDB_RGB.sh $HOST_DATA_DIR/raw_data $HOST_DATA_DIR/processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download the split files and unrar\n",
    "#!wget -P $HOST_DATA_DIR http://serre-lab.clps.brown.edu/wp-content/uploads/2013/10/test_train_splits.ra\n",
    "#!mkdir -p $HOST_DATA_DIR/splits && unrar x $HOST_DATA_DIR/test_train_splits.rar $HOST_DATA_DIR/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-05-10 23:16:08--  https://github.com/shokoufeh-monjezi/TAOData/releases/download/v1.0/test_train_splits.zip\n",
      "Resolving github.com (github.com)... 140.82.113.3\n",
      "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/490854586/583fd76f-6b90-4a6b-b85b-282ff2c9e448?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220510T231608Z&X-Amz-Expires=300&X-Amz-Signature=e53a04d97818e24ff3ffe09b58eed1fe4f374ad1aa72a966524638abff05a818&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=490854586&response-content-disposition=attachment%3B%20filename%3Dtest_train_splits.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2022-05-10 23:16:08--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/490854586/583fd76f-6b90-4a6b-b85b-282ff2c9e448?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220510%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220510T231608Z&X-Amz-Expires=300&X-Amz-Signature=e53a04d97818e24ff3ffe09b58eed1fe4f374ad1aa72a966524638abff05a818&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=490854586&response-content-disposition=attachment%3B%20filename%3Dtest_train_splits.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 222062 (217K) [application/octet-stream]\n",
      "Saving to: ‘/home/jupyter/action_recognition_net/data/test_train_splits.zip.1’\n",
      "\n",
      "test_train_splits.z 100%[===================>] 216.86K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2022-05-10 23:16:08 (8.50 MB/s) - ‘/home/jupyter/action_recognition_net/data/test_train_splits.zip.1’ saved [222062/222062]\n",
      "\n",
      "Archive:  /home/jupyter/action_recognition_net/data/test_train_splits.zip\n",
      "   creating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/\n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/brush_hair_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/brush_hair_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/brush_hair_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/cartwheel_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/cartwheel_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/cartwheel_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/catch_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/catch_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/catch_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/chew_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/chew_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/chew_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/clap_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/clap_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/clap_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_stairs_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_stairs_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_stairs_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/climb_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dive_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dive_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dive_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/draw_sword_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/draw_sword_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/draw_sword_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dribble_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dribble_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/dribble_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/drink_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/drink_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/drink_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/eat_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/eat_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/eat_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fall_floor_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fall_floor_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fall_floor_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fencing_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fencing_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/fencing_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/flic_flac_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/flic_flac_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/flic_flac_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/golf_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/golf_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/golf_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/handstand_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/handstand_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/handstand_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hit_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hit_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hit_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hug_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hug_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/hug_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/jump_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/jump_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/jump_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_ball_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_ball_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_ball_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kick_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kiss_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kiss_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/kiss_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/laugh_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/laugh_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/laugh_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pick_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pick_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pick_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pour_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pour_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pour_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pullup_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pullup_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pullup_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/punch_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/punch_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/punch_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/push_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/push_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/push_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pushup_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pushup_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/pushup_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_bike_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_bike_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_bike_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_horse_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_horse_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/ride_horse_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/run_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/run_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/run_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shake_hands_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shake_hands_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shake_hands_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_ball_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_ball_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_ball_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_bow_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_bow_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_bow_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_gun_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_gun_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/shoot_gun_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sit_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sit_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sit_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/situp_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/situp_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/situp_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smile_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smile_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smile_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smoke_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smoke_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/smoke_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/somersault_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/somersault_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/somersault_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/stand_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/stand_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/stand_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/swing_baseball_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/swing_baseball_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/swing_baseball_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_exercise_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_exercise_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_exercise_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/sword_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/talk_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/talk_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/talk_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/throw_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/throw_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/throw_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/turn_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/turn_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/turn_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/walk_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/walk_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/walk_test_split3.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/wave_test_split1.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/wave_test_split2.txt  \n",
      "  inflating: /home/jupyter/action_recognition_net/data/splits/test_train_splits/testTrainMulti_7030_splits/wave_test_split3.txt  \n"
     ]
    }
   ],
   "source": [
    "# download the split files and unrar\n",
    "!wget -P $HOST_DATA_DIR https://github.com/shokoufeh-monjezi/TAOData/releases/download/v1.0/test_train_splits.zip\n",
    "!mkdir -p $HOST_DATA_DIR/splits && unzip  $HOST_DATA_DIR/test_train_splits.zip -d $HOST_DATA_DIR/splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1: \n",
      " Train: 140\n",
      " Test: 60\n"
     ]
    }
   ],
   "source": [
    "# run split_HMDB to generate training split\n",
    "!cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && python3 ./split_dataset.py $HOST_DATA_DIR/processed_data $HOST_DATA_DIR/splits/test_train_splits/testTrainMulti_7030_splits $HOST_DATA_DIR/train  $HOST_DATA_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16\n",
      "drwxr-xr-x 72 jupyter jupyter  4096 May 10 23:20 fall_floor\n",
      "drwxr-xr-x 72 jupyter jupyter 12288 May 10 23:20 ride_bike\n",
      "total 280\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 '#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_0'\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 '#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_1'\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 '#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_ba_med_3'\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 '#437_How_To_Ride_A_Bike_ride_bike_f_cm_np1_fr_med_2'\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ba_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_fr_med_6\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_fr_med_7\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_le_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ri_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1989_Tour_de_France_Final_Time_Trial_ride_bike_f_cm_np1_ri_med_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  1996_Tour_de_France_-_Indurain_Cracks_ride_bike_f_cm_np1_ri_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Bicycle_Tips_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Bicycle_Tips_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Bicycle_Tips_ride_bike_f_cm_np1_ri_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  CSC_and_the_2007__Sydney_to_the_Gong__bike_ride_ride_bike_f_cm_np1_ri_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ba_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_fr_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ri_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  David_beim_Fahrrad_fahren_X_x_ride_bike_f_cm_np1_ri_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Fahrrad_Eigenbau_ride_bike_f_cm_np1_le_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Fahrrad_Eigenbau_ride_bike_f_cm_np1_ri_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Fahrrad_fahren_ride_bike_f_cm_np2_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07  Fahrrad_fahren_ride_bike_f_cm_np2_le_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Fahrrad_fahren_ride_bike_f_cm_np2_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Fahrrad_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Finding_Forrester_4_ride_bike_f_cm_np1_fr_bad_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Finding_Forrester_5_ride_bike_f_cm_np1_fr_bad_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Finding_Forrester_5_ride_bike_f_cm_np1_fr_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  I_want_to_ride_my_bicycle_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Justin_lernt_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Justin_lernt_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_6\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np1_le_med_7\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_cm_np4_fr_med_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_f_nm_np1_fr_med_8\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_l_cm_np1_le_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Kraftwerk_-_Tour_de_france_1983_Alternative_video_ride_bike_l_cm_np1_le_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_12\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_13\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_ba_med_7\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_fr_med_10\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_bad_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np1_le_med_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ba_med_11\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_fr_med_15\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_14\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_16\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ri_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_f_cm_np2_ri_med_6\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_l_cm_np1_ba_med_8\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Radfahren_um_die_Aggertalsperre_06_09_2009_ride_bike_l_cm_np1_ba_med_9\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np1_ba_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np2_fr_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08  Tour_de_France_2003_-_Armstrong_attacks_Ullrich_after_Fall_ride_bike_f_cm_np2_fr_med_1\n",
      "total 8\n",
      "drwxr-xr-x 32 jupyter jupyter 4096 May 10 23:20 fall_floor\n",
      "drwxr-xr-x 32 jupyter jupyter 4096 May 10 23:20 ride_bike\n",
      "total 120\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:07 Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_7\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_6\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_9\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_8\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_10\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_11\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Schuodde_kann_kein_Fahrrad_fahren_ride_bike_l_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_bad_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_4\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_5\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ri_bad_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_fr_med_3\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_0\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 lady_on_bike_ride_bike_f_cm_np1_ba_med_1\n",
      "drwxr-xr-x 3 jupyter jupyter 4096 May 10 23:08 lady_on_bike_ride_bike_f_cm_np1_ri_med_0\n"
     ]
    }
   ],
   "source": [
    "# verify\n",
    "!ls -l $HOST_DATA_DIR/train\n",
    "!ls -l $HOST_DATA_DIR/train/ride_bike\n",
    "!ls -l $HOST_DATA_DIR/test\n",
    "!ls -l $HOST_DATA_DIR/test/ride_bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide scripts to preprocess [SHAD](https://best.sjtu.edu.cn/Data/View/990) dataset. The following cells for processing SHAD dataset is `Optional`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OPTIONAL:` Download the app based on NVOF SDK to generate optical flow. It is packaged with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!echo <passwd> | sudo -S apt install -y libfreeimage-dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create train and test dir for raw videos and labels\n",
    "# !mkdir -p $HOST_DATA_DIR/train_raw && mkdir -p $HOST_DATA_DIR/test_raw\n",
    "# # download the dataset and unrar the files\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Bend-train.rar\n",
    "# !unrar x $HOST_DATA_DIR/Bend-train.rar $HOST_DATA_DIR/train_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Bend-test.rar\n",
    "# !unrar x $HOST_DATA_DIR/Bend-test.rar $HOST_DATA_DIR/test_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Fall-train.rar\n",
    "# !unrar x $HOST_DATA_DIR/Fall-train.rar $HOST_DATA_DIR/train_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Fall-test.rar\n",
    "# !unrar x $HOST_DATA_DIR/Fall-test.rar $HOST_DATA_DIR/test_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Squa-train.rar\n",
    "# !unrar x $HOST_DATA_DIR/Squa-train.rar $HOST_DATA_DIR/train_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Squa-test.rar\n",
    "# !unrar x $HOST_DATA_DIR/Squa-test.rar $HOST_DATA_DIR/test_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Sits-train.rar\n",
    "# !unrar x $HOST_DATA_DIR/Sits-train.rar $HOST_DATA_DIR/train_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Sits-test.rar\n",
    "# !unrar x $HOST_DATA_DIR/Sits-test.rar $HOST_DATA_DIR/test_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Walk-train.rar\n",
    "# !unrar x $HOST_DATA_DIR/Walk-train.rar $HOST_DATA_DIR/train_raw\n",
    "# !wget -P $HOST_DATA_DIR https://best.sjtu.edu.cn/Assets/userfiles/sys_eb538c1c-65ff-4e82-8e6a-a1ef01127fed/files/ZIP/Walk-test.rar\n",
    "# !unrar x $HOST_DATA_DIR/Walk-test.rar $HOST_DATA_DIR/test_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`OPTIONAL` Run the process script for SHAD. \n",
    "\n",
    "`IMPORTANT NOTE`: to run the `process_SHAD.sh` generating optical flow, a Turing or Ampere above GPU is needed. You could run with `preprocess_SHAD_RGB.sh` to play with RGB frames only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && ./preprocess_SHAD.sh $HOST_DATA_DIR/train_raw $HOST_DATA_DIR/train\n",
    "# ! cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && ./preprocess_SHAD_RGB.sh $HOST_DATA_DIR/train_raw $HOST_DATA_DIR/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && ./preprocess_SHAD.sh $HOST_DATA_DIR/test_raw $HOST_DATA_DIR/test\n",
    "# ! cd tao_toolkit_recipes/tao_action_recognition/data_generation/ && ./preprocess_SHAD_RGB.sh $HOST_DATA_DIR/test_raw $HOST_DATA_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # verify\n",
    "# !ls -l $HOST_DATA_DIR/train\n",
    "# !ls -l $HOST_DATA_DIR/train/bend\n",
    "# !ls -l $HOST_DATA_DIR/test\n",
    "# !ls -l $HOST_DATA_DIR/test/bend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Download pretrained model from NGC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use NGC CLI to get the pre-trained models. For more details, go to https://ngc.nvidia.com and click the SETUP on the navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLI=ngccli_cat_linux.zip\n",
      "--2022-05-10 23:21:13--  https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip\n",
      "Resolving ngc.nvidia.com (ngc.nvidia.com)... 108.156.91.29, 108.156.91.35, 108.156.91.12, ...\n",
      "Connecting to ngc.nvidia.com (ngc.nvidia.com)|108.156.91.29|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 32589718 (31M) [application/zip]\n",
      "Saving to: ‘/home/jupyter/action_recognition_net/results/ngccli/ngccli_cat_linux.zip’\n",
      "\n",
      "ngccli_cat_linux.zi 100%[===================>]  31.08M  63.9MB/s    in 0.5s    \n",
      "\n",
      "2022-05-10 23:21:14 (63.9 MB/s) - ‘/home/jupyter/action_recognition_net/results/ngccli/ngccli_cat_linux.zip’ saved [32589718/32589718]\n",
      "\n",
      "Archive:  /home/jupyter/action_recognition_net/results/ngccli/ngccli_cat_linux.zip\n",
      "  inflating: /home/jupyter/action_recognition_net/results/ngccli/ngc  \n",
      " extracting: /home/jupyter/action_recognition_net/results/ngccli/ngc.md5  \n"
     ]
    }
   ],
   "source": [
    "# Installing NGC CLI on the local machine.\n",
    "## Download and install\n",
    "import os\n",
    "%env CLI=ngccli_cat_linux.zip\n",
    "!mkdir -p $HOST_RESULTS_DIR/ngccli\n",
    "\n",
    "# Remove any previously existing CLI installations\n",
    "!rm -rf $HOST_RESULTS_DIR/ngccli/*\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $HOST_RESULTS_DIR/ngccli\n",
    "!unzip -u \"$HOST_RESULTS_DIR/ngccli/$CLI\" -d $HOST_RESULTS_DIR/ngccli/\n",
    "!rm $HOST_RESULTS_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli:{}\".format(os.getenv(\"HOST_RESULTS_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| Versi | Accur | Epoch | Batch | GPU   | Memor | File  | Statu | Creat |\n",
      "| on    | acy   | s     | Size  | Model | y Foo | Size  | s     | ed    |\n",
      "|       |       |       |       |       | tprin |       |       | Date  |\n",
      "|       |       |       |       |       | t     |       |       |       |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| train | 88.0  | 120   | 1     | V100  | 426.2 | 426.1 | UPLOA | Nov   |\n",
      "| able_ |       |       |       |       |       | 6 MB  | D_COM | 23,   |\n",
      "| v1.0  |       |       |       |       |       |       | PLETE | 2021  |\n",
      "| deplo | 90.0  | 120   | 1     | V100  | 170.3 | 170.3 | UPLOA | Oct   |\n",
      "| yable |       |       |       |       |       | 3 MB  | D_COM | 22,   |\n",
      "| _v1.0 |       |       |       |       |       |       | PLETE | 2021  |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "!ngc registry model list nvidia/tao/actionrecognitionnet:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $HOST_RESULTS_DIR/pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 363.87 MB in 17s, Download speed: 21.38 MB/s               \n",
      "----------------------------------------------------\n",
      "Transfer id: actionrecognitionnet_vtrainable_v1.0 Download status: Completed.\n",
      "Downloaded local path: /home/jupyter/action_recognition_net/results/pretrained/actionrecognitionnet_vtrainable_v1.0\n",
      "Total files downloaded: 2 \n",
      "Total downloaded size: 363.87 MB\n",
      "Started at: 2022-05-10 23:21:47.568071\n",
      "Completed at: 2022-05-10 23:22:04.591495\n",
      "Duration taken: 17s\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pull pretrained model from NGC \n",
    "!ngc registry model download-version \"nvidia/tao/actionrecognitionnet:trainable_v1.0\" --dest $HOST_RESULTS_DIR/pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check that model is downloaded into dir.\n",
      "total 436396\n",
      "-rw------- 1 jupyter jupyter 114846245 May 10 23:22 resnet18_2d_rgb_hmdb5_32.tlt\n",
      "-rw------- 1 jupyter jupyter 332019621 May 10 23:22 resnet18_3d_rgb_hmdb5_32.tlt\n"
     ]
    }
   ],
   "source": [
    "print(\"Check that model is downloaded into dir.\")\n",
    "!ls -l $HOST_RESULTS_DIR/pretrained/actionrecognitionnet_vtrainable_v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Provide training specification <a class=\"anchor\" id=\"head-2\"></a>\n",
    "\n",
    "We provide specification files to configure the training parameters including:\n",
    "\n",
    "* model_config: configure the model setting\n",
    "    * model_type: type of model, rgb/of/joint\n",
    "    * backbone: resnet18/34/50/101/152 \n",
    "    * rgb_seq_length: length of RGB input sequence\n",
    "    * input_type: 2d/3d\n",
    "    * sample_strategy: consecutive\n",
    "    * dropout_ratio: probability to drop the hidden units\n",
    "* train_config: configure the training hyperparameters\n",
    "    * optim_config\n",
    "    * epochs\n",
    "    * checkpoint_interval\n",
    "* dataset_config: configure the dataset and augmentation methods\n",
    "    * train_dataset_dir\n",
    "    * val_dataset_dir\n",
    "    * label_map: map the class label to id\n",
    "    * output_shape\n",
    "    * batch_size\n",
    "    * workers: number of workers to do data loading\n",
    "    * clips_per_video: number of clips to be sampled from single video\n",
    "    * augmentation_config\n",
    "\n",
    "Please refer to the TAO documentation about ActionRecognitionNet to get all the parameters that are configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_dir: /home/jupyter/action_recognition_net/results/rgb_3d_ptm\n",
      "encryption_key: nvidia_tao\n",
      "model_config:\n",
      "  model_type: rgb\n",
      "  backbone: resnet18\n",
      "  rgb_seq_length: 3\n",
      "  input_type: 3d\n",
      "  sample_strategy: consecutive\n",
      "  dropout_ratio: 0.0\n",
      "train_config:\n",
      "  optim:\n",
      "    lr: 0.001\n",
      "    momentum: 0.9\n",
      "    weight_decay: 0.0001\n",
      "    lr_scheduler: MultiStep\n",
      "    lr_steps: [5, 15, 20]\n",
      "    lr_decay: 0.1\n",
      "  epochs: 20\n",
      "  checkpoint_interval: 1\n",
      "dataset_config:\n",
      "  train_dataset_dir: /home/jupyter/action_recognition_net/data/train\n",
      "  val_dataset_dir: /home/jupyter/action_recognition_net/data/test\n",
      "  label_map:\n",
      "    fall_floor: 0\n",
      "    ride_bike: 1\n",
      "  output_shape:\n",
      "  - 224\n",
      "  - 224\n",
      "  batch_size: 8\n",
      "  workers: 1\n",
      "  clips_per_video: 5\n",
      "  augmentation_config:\n",
      "    train_crop_type: no_crop\n",
      "    horizontal_flip_prob: 0.5\n",
      "    rgb_input_mean: [0.5]\n",
      "    rgb_input_std: [0.5]\n",
      "    val_center_crop: False\n"
     ]
    }
   ],
   "source": [
    "!cat $HOST_SPECS_DIR/train_rgb_3d_finetune.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run TAO training <a class=\"anchor\" id=\"head-3\"></a>\n",
    "* Provide the sample spec file and the output directory location for models\n",
    "* WARNING: training will take several hours or one day to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Train 3D model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide pretrained RGB-only model trained on HMDB5 dataset. With the pretrained model, we can even get better accuracy with less epochs.\n",
    "\n",
    "`KNOWN ISSUE`: \n",
    "- 1) The training log will be corrupted by pytorch warning in the notebook:\n",
    "\n",
    "     `[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)` \n",
    "     \n",
    "     To see the full log in std out, please run the command in terminal. \n",
    "- 2) \"=\" in the checkpoint file name should removed before using the checkpoint in command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RGB only model with PTM\n",
      "/home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/scripts/train.py:76: UserWarning: \n",
      "'train_rgb_3d_finetune.yaml' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "loading trained weights from /home/jupyter/action_recognition_net/results/pretrained/actionrecognitionnet_vtrainable_v1.0/resnet18_3d_rgb_hmdb5_32.tlt\n",
      "ResNet3d(\n",
      "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=2, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc_cls): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "/opt/conda/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:446: UserWarning: Checkpoint directory /home/jupyter/action_recognition_net/results/rgb_3d_ptm exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:487: LightningDeprecationWarning: Argument `period` in `ModelCheckpoint` is deprecated in v1.3 and will be removed in v1.5. Please use `every_n_epochs` instead.\n",
      "  rank_zero_deprecation(\n",
      "Train dataset samples: 140\n",
      "Validation dataset samples: 60\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | model          | ResNet3d | 33.2 M\n",
      "1 | train_accuracy | Accuracy | 0     \n",
      "2 | val_accuracy   | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "33.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "33.2 M    Total params\n",
      "132.744   Total estimated model params size (MB)\n",
      "Validation sanity check: 0it [00:00, ?it/s]/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:105: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Epoch 0:  91%|██████████▉ | 87/96 [00:30<00:03,  2.87it/s, loss=0.0583, v_num=5]Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 0:  92%|███████████ | 88/96 [00:30<00:02,  2.90it/s, loss=0.0565, v_num=5]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 0:  94%|███████████▎| 90/96 [00:30<00:02,  2.94it/s, loss=0.0565, v_num=5]\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.77it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  4.00it/s]\u001b[A\n",
      "Epoch 0:  97%|███████████▋| 93/96 [00:31<00:01,  2.97it/s, loss=0.0565, v_num=5]\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.76it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.05it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 96/96 [00:32<00:00,  3.01it/s, loss=0.0565, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 1:   0%| | 0/96 [00:00<00:00, 3515.76it/s, loss=0.0565, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 1:  91%|▉| 87/96 [00:26<00:02,  3.35it/s, loss=0.0525, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 1:  92%|▉| 88/96 [00:26<00:02,  3.38it/s, loss=0.05, v_num=5, val_loss=0.0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 1:  94%|▉| 90/96 [00:26<00:01,  3.42it/s, loss=0.05, v_num=5, val_loss=0.0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.70it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.97it/s]\u001b[A\n",
      "Epoch 1:  97%|▉| 93/96 [00:27<00:00,  3.45it/s, loss=0.05, v_num=5, val_loss=0.0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.69it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 96/96 [00:27<00:00,  3.48it/s, loss=0.05, v_num=5, val_loss=0.0\u001b[A\n",
      "Epoch 2:   0%| | 0/96 [00:00<00:00, 3486.54it/s, loss=0.05, v_num=5, val_loss=0.[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 2:  91%|▉| 87/96 [00:25<00:02,  3.41it/s, loss=0.0196, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 2:  92%|▉| 88/96 [00:25<00:02,  3.44it/s, loss=0.0434, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 2:  94%|▉| 90/96 [00:26<00:01,  3.48it/s, loss=0.0434, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.71it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  4.01it/s]\u001b[A\n",
      "Epoch 2:  97%|▉| 93/96 [00:26<00:00,  3.51it/s, loss=0.0434, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.71it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.09it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 96/96 [00:27<00:00,  3.55it/s, loss=0.0434, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 3:   0%| | 0/96 [00:00<00:00, 3858.61it/s, loss=0.0434, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 3:  91%|▉| 87/96 [00:21<00:02,  4.06it/s, loss=0.0169, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 3:  92%|▉| 88/96 [00:21<00:01,  4.10it/s, loss=0.0157, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 3:  94%|▉| 90/96 [00:22<00:01,  4.13it/s, loss=0.0157, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.66it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.82it/s]\u001b[A\n",
      "Epoch 3:  97%|▉| 93/96 [00:22<00:00,  4.15it/s, loss=0.0157, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.50it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.85it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 96/96 [00:23<00:00,  4.17it/s, loss=0.0157, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 4:   0%| | 0/96 [00:00<00:00, 3238.84it/s, loss=0.0157, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 4:  91%|▉| 87/96 [00:20<00:02,  4.33it/s, loss=0.016, v_num=5, val_loss=0.Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 4:  92%|▉| 88/96 [00:20<00:01,  4.37it/s, loss=0.0164, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 4:  94%|▉| 90/96 [00:20<00:01,  4.41it/s, loss=0.0164, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.74it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.97it/s]\u001b[A\n",
      "Epoch 4:  97%|▉| 93/96 [00:21<00:00,  4.42it/s, loss=0.0164, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.68it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.98it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 96/96 [00:21<00:00,  4.43it/s, loss=0.0164, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 5:   0%| | 0/96 [00:00<00:00, 3000.22it/s, loss=0.0164, v_num=5, val_loss=\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 5:  91%|▉| 87/96 [00:20<00:02,  4.32it/s, loss=0.0171, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 5:  92%|▉| 88/96 [00:20<00:01,  4.36it/s, loss=0.0173, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 5:  94%|▉| 90/96 [00:20<00:01,  4.39it/s, loss=0.0173, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.71it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.90it/s]\u001b[A\n",
      "Epoch 5:  97%|▉| 93/96 [00:21<00:00,  4.40it/s, loss=0.0173, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.50it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.94it/s]\u001b[A\n",
      "Epoch 5: 100%|█| 96/96 [00:21<00:00,  4.42it/s, loss=0.0173, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 6:   0%| | 0/96 [00:00<00:00, 3637.73it/s, loss=0.0173, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 6:  91%|▉| 87/96 [00:19<00:02,  4.41it/s, loss=0.0183, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 6:  92%|▉| 88/96 [00:20<00:01,  4.45it/s, loss=0.0181, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 6:  94%|▉| 90/96 [00:20<00:01,  4.48it/s, loss=0.0181, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.79it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  4.02it/s]\u001b[A\n",
      "Epoch 6:  97%|▉| 93/96 [00:20<00:00,  4.50it/s, loss=0.0181, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.75it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.10it/s]\u001b[A\n",
      "Epoch 6: 100%|█| 96/96 [00:21<00:00,  4.51it/s, loss=0.0181, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 7:   0%| | 0/96 [00:00<00:00, 3079.52it/s, loss=0.0181, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 7:  91%|▉| 87/96 [00:18<00:01,  4.81it/s, loss=0.0127, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 7:  92%|▉| 88/96 [00:18<00:01,  4.85it/s, loss=0.0162, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 7:  94%|▉| 90/96 [00:18<00:01,  4.88it/s, loss=0.0162, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.68it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.89it/s]\u001b[A\n",
      "Epoch 7:  97%|▉| 93/96 [00:19<00:00,  4.87it/s, loss=0.0162, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.52it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.95it/s]\u001b[A\n",
      "Epoch 7: 100%|█| 96/96 [00:19<00:00,  4.88it/s, loss=0.0162, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 8:   0%| | 0/96 [00:00<00:00, 2535.85it/s, loss=0.0162, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 8:  91%|▉| 87/96 [00:19<00:01,  4.61it/s, loss=0.00908, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 8:  92%|▉| 88/96 [00:19<00:01,  4.64it/s, loss=0.0105, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 8:  94%|▉| 90/96 [00:19<00:01,  4.68it/s, loss=0.0105, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.77it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.98it/s]\u001b[A\n",
      "Epoch 8:  97%|▉| 93/96 [00:20<00:00,  4.68it/s, loss=0.0105, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.71it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.09it/s]\u001b[A\n",
      "Epoch 8: 100%|█| 96/96 [00:20<00:00,  4.69it/s, loss=0.0105, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 9:   0%| | 0/96 [00:00<00:00, 3701.95it/s, loss=0.0105, v_num=5, val_loss=[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 9:  91%|▉| 87/96 [00:18<00:01,  4.82it/s, loss=0.0134, v_num=5, val_loss=0Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 9:  92%|▉| 88/96 [00:18<00:01,  4.86it/s, loss=0.0311, v_num=5, val_loss=0\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 9:  94%|▉| 90/96 [00:18<00:01,  4.89it/s, loss=0.0311, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.67it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.87it/s]\u001b[A\n",
      "Epoch 9:  97%|▉| 93/96 [00:19<00:00,  4.88it/s, loss=0.0311, v_num=5, val_loss=0\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.63it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "Epoch 9: 100%|█| 96/96 [00:19<00:00,  4.89it/s, loss=0.0311, v_num=5, val_loss=0\u001b[A\n",
      "Epoch 10:   0%| | 0/96 [00:00<00:00, 3231.36it/s, loss=0.0311, v_num=5, val_loss[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 10:  91%|▉| 87/96 [00:19<00:01,  4.62it/s, loss=0.00553, v_num=5, val_lossAdjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 10:  92%|▉| 88/96 [00:19<00:01,  4.66it/s, loss=0.00782, v_num=5, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 10:  94%|▉| 90/96 [00:19<00:01,  4.69it/s, loss=0.00782, v_num=5, val_loss\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.75it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.99it/s]\u001b[A\n",
      "Epoch 10:  97%|▉| 93/96 [00:20<00:00,  4.69it/s, loss=0.00782, v_num=5, val_loss\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.71it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.04it/s]\u001b[A\n",
      "Epoch 10: 100%|█| 96/96 [00:20<00:00,  4.70it/s, loss=0.00782, v_num=5, val_loss\u001b[A\n",
      "Epoch 11:   0%| | 0/96 [00:00<00:00, 2570.04it/s, loss=0.00782, v_num=5, val_los\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 11:  91%|▉| 87/96 [00:17<00:01,  4.98it/s, loss=0.0106, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 11:  92%|▉| 88/96 [00:17<00:01,  5.02it/s, loss=0.0176, v_num=5, val_loss=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 11:  94%|▉| 90/96 [00:18<00:01,  5.05it/s, loss=0.0176, v_num=5, val_loss=\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.68it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.90it/s]\u001b[A\n",
      "Epoch 11:  97%|▉| 93/96 [00:18<00:00,  5.04it/s, loss=0.0176, v_num=5, val_loss=\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.67it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.06it/s]\u001b[A\n",
      "Epoch 11: 100%|█| 96/96 [00:19<00:00,  5.04it/s, loss=0.0176, v_num=5, val_loss=\u001b[A\n",
      "Epoch 12:   0%| | 0/96 [00:00<00:00, 3782.06it/s, loss=0.0176, v_num=5, val_loss[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 12:  91%|▉| 87/96 [00:17<00:01,  5.04it/s, loss=0.00654, v_num=5, val_lossAdjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 12:  92%|▉| 88/96 [00:17<00:01,  5.08it/s, loss=0.00649, v_num=5, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 12:  94%|▉| 90/96 [00:17<00:01,  5.11it/s, loss=0.00649, v_num=5, val_loss\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.75it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  4.00it/s]\u001b[A\n",
      "Epoch 12:  97%|▉| 93/96 [00:18<00:00,  5.10it/s, loss=0.00649, v_num=5, val_loss\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.64it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.01it/s]\u001b[A\n",
      "Epoch 12: 100%|█| 96/96 [00:19<00:00,  5.10it/s, loss=0.00649, v_num=5, val_loss\u001b[A\n",
      "Epoch 13:   0%| | 0/96 [00:00<00:00, 3480.75it/s, loss=0.00649, v_num=5, val_los\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 13:  91%|▉| 87/96 [00:17<00:01,  5.11it/s, loss=0.00572, v_num=5, val_lossAdjusting learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 13:  92%|▉| 88/96 [00:17<00:01,  5.15it/s, loss=0.00537, v_num=5, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 13:  94%|▉| 90/96 [00:17<00:01,  5.17it/s, loss=0.00537, v_num=5, val_loss\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.71it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.93it/s]\u001b[A\n",
      "Epoch 13:  97%|▉| 93/96 [00:18<00:00,  5.16it/s, loss=0.00537, v_num=5, val_loss\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.63it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.91it/s]\u001b[A\n",
      "Epoch 13: 100%|█| 96/96 [00:18<00:00,  5.14it/s, loss=0.00537, v_num=5, val_loss\u001b[A\n",
      "Epoch 14:   0%| | 0/96 [00:00<00:00, 2759.41it/s, loss=0.00537, v_num=5, val_los\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 14:  91%|▉| 87/96 [00:17<00:01,  5.01it/s, loss=0.0109, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 14:  92%|▉| 88/96 [00:17<00:01,  5.06it/s, loss=0.0108, v_num=5, val_loss=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 14:  94%|▉| 90/96 [00:17<00:01,  5.09it/s, loss=0.0108, v_num=5, val_loss=\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.74it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.96it/s]\u001b[A\n",
      "Epoch 14:  97%|▉| 93/96 [00:18<00:00,  5.08it/s, loss=0.0108, v_num=5, val_loss=\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.59it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.93it/s]\u001b[A\n",
      "Epoch 14: 100%|█| 96/96 [00:19<00:00,  5.07it/s, loss=0.0108, v_num=5, val_loss=\u001b[A\n",
      "Epoch 15:   0%| | 0/96 [00:00<00:00, 3581.81it/s, loss=0.0108, v_num=5, val_loss[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 15:  91%|▉| 87/96 [00:17<00:01,  4.99it/s, loss=0.0315, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 15:  92%|▉| 88/96 [00:17<00:01,  5.03it/s, loss=0.0315, v_num=5, val_loss=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 15:  94%|▉| 90/96 [00:17<00:01,  5.06it/s, loss=0.0315, v_num=5, val_loss=\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.81it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  4.02it/s]\u001b[A\n",
      "Epoch 15:  97%|▉| 93/96 [00:18<00:00,  5.05it/s, loss=0.0315, v_num=5, val_loss=\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.71it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.08it/s]\u001b[A\n",
      "Epoch 15: 100%|█| 96/96 [00:19<00:00,  5.06it/s, loss=0.0315, v_num=5, val_loss=\u001b[A\n",
      "Epoch 16:   0%| | 0/96 [00:00<00:00, 3644.05it/s, loss=0.0315, v_num=5, val_loss[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 16:  91%|▉| 87/96 [00:16<00:01,  5.21it/s, loss=0.0115, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 16:  92%|▉| 88/96 [00:16<00:01,  5.25it/s, loss=0.0111, v_num=5, val_loss=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 16:  94%|▉| 90/96 [00:17<00:01,  5.27it/s, loss=0.0111, v_num=5, val_loss=\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.59it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.83it/s]\u001b[A\n",
      "Epoch 16:  97%|▉| 93/96 [00:17<00:00,  5.24it/s, loss=0.0111, v_num=5, val_loss=\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.50it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  5.01it/s]\u001b[A\n",
      "Epoch 16: 100%|█| 96/96 [00:18<00:00,  5.24it/s, loss=0.0111, v_num=5, val_loss=\u001b[A\n",
      "Epoch 17:   0%| | 0/96 [00:00<00:00, 3323.54it/s, loss=0.0111, v_num=5, val_loss\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 17:  91%|▉| 87/96 [00:16<00:01,  5.37it/s, loss=0.0196, v_num=5, val_loss=Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 17:  92%|▉| 88/96 [00:16<00:01,  5.41it/s, loss=0.0191, v_num=5, val_loss=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 17:  94%|▉| 90/96 [00:16<00:01,  5.43it/s, loss=0.0191, v_num=5, val_loss=\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.68it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.90it/s]\u001b[A\n",
      "Epoch 17:  97%|▉| 93/96 [00:17<00:00,  5.41it/s, loss=0.0191, v_num=5, val_loss=\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.63it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.97it/s]\u001b[A\n",
      "Epoch 17: 100%|█| 96/96 [00:17<00:00,  5.40it/s, loss=0.0191, v_num=5, val_loss=\u001b[A\n",
      "Epoch 18:   0%| | 0/96 [00:00<00:00, 3057.07it/s, loss=0.0191, v_num=5, val_loss[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 18:  91%|▉| 87/96 [00:16<00:01,  5.26it/s, loss=0.00949, v_num=5, val_lossAdjusting learning rate of group 0 to 1.0000e-05.\n",
      "Epoch 18:  92%|▉| 88/96 [00:16<00:01,  5.30it/s, loss=0.00734, v_num=5, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 18:  94%|▉| 90/96 [00:17<00:01,  5.33it/s, loss=0.00734, v_num=5, val_loss\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.73it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.86it/s]\u001b[A\n",
      "Epoch 18:  97%|▉| 93/96 [00:17<00:00,  5.30it/s, loss=0.00734, v_num=5, val_loss\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.61it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.96it/s]\u001b[A\n",
      "Epoch 18: 100%|█| 96/96 [00:18<00:00,  5.30it/s, loss=0.00734, v_num=5, val_loss\u001b[A\n",
      "Epoch 19:   0%| | 0/96 [00:00<00:00, 3618.90it/s, loss=0.00734, v_num=5, val_los[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "Epoch 19:  91%|▉| 87/96 [00:16<00:01,  5.29it/s, loss=0.00807, v_num=5, val_lossAdjusting learning rate of group 0 to 1.0000e-06.\n",
      "Epoch 19:  92%|▉| 88/96 [00:16<00:01,  5.33it/s, loss=0.00814, v_num=5, val_loss\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|                                         | 0/8 [00:00<?, ?it/s]\u001b[A[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "\n",
      "Epoch 19:  94%|▉| 90/96 [00:17<00:01,  5.35it/s, loss=0.00814, v_num=5, val_loss\u001b[A\n",
      "Validating:  25%|████████▎                        | 2/8 [00:00<00:01,  3.70it/s]\u001b[A\n",
      "Validating:  38%|████████████▍                    | 3/8 [00:00<00:01,  3.94it/s]\u001b[A\n",
      "Epoch 19:  97%|▉| 93/96 [00:17<00:00,  5.32it/s, loss=0.00814, v_num=5, val_loss\u001b[A\n",
      "Validating:  62%|████████████████████▋            | 5/8 [00:01<00:00,  4.56it/s]\u001b[A\n",
      "Validating:  75%|████████████████████████▊        | 6/8 [00:01<00:00,  4.99it/s]\u001b[A\n",
      "Epoch 19: 100%|█| 96/96 [00:18<00:00,  5.31it/s, loss=0.00814, v_num=5, val_loss\u001b[A\n",
      "Epoch 19: 100%|█| 96/96 [00:21<00:00,  4.59it/s, loss=0.00814, v_num=5, val_loss\u001b[A\n"
     ]
    }
   ],
   "source": [
    "print(\"Train RGB only model with PTM\")\n",
    "!action_recognition train \\\n",
    "                  -e $HOST_SPECS_DIR/train_rgb_3d_finetune.yaml \\\n",
    "                  -r $HOST_RESULTS_DIR/rgb_3d_ptm \\\n",
    "                  -k $KEY \\\n",
    "                  model_config.rgb_pretrained_model_path=$HOST_RESULTS_DIR/pretrained/actionrecognitionnet_vtrainable_v1.0/resnet18_3d_rgb_hmdb5_32.tlt  \\\n",
    "                  model_config.rgb_pretrained_num_classes=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encrypted checkpoints:\n",
      "---------------------\n",
      "total 14G\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:44 'ar_model_epoch=00-val_loss=0.03.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:45 'ar_model_epoch=01-val_loss=0.04.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:46 'ar_model_epoch=02-val_loss=0.06.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:47 'ar_model_epoch=03-val_loss=0.04.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:47 'ar_model_epoch=04-val_loss=0.21.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:47 'ar_model_epoch=00-val_loss=0.05.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:48 'ar_model_epoch=05-val_loss=0.12.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:48 'ar_model_epoch=01-val_loss=0.03.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:48 'ar_model_epoch=06-val_loss=0.16.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:48 'ar_model_epoch=02-val_loss=0.05.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:49 'ar_model_epoch=07-val_loss=0.15.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:49 'ar_model_epoch=03-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:49 'ar_model_epoch=08-val_loss=0.14.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:49 'ar_model_epoch=04-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=09-val_loss=0.12.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=05-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=10-val_loss=0.09.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=06-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=11-val_loss=0.07.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:50 'ar_model_epoch=07-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:51 'ar_model_epoch=12-val_loss=0.10.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:51 'ar_model_epoch=08-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:51 'ar_model_epoch=13-val_loss=0.08.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:51 'ar_model_epoch=09-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=14-val_loss=0.08.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=10-val_loss=0.02.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=15-val_loss=0.12.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=11-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=16-val_loss=0.06.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:52 'ar_model_epoch=12-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=13-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=17-val_loss=0.08.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=18-val_loss=0.10.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=14-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=19-val_loss=0.08.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:53 'ar_model_epoch=15-val_loss=0.01.tlt'\n",
      "drwxr-xr-x 9 jupyter jupyter 4.0K May 11 22:54  lightning_logs\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:54 'ar_model_epoch=16-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:54 'ar_model_epoch=00-val_loss=0.06.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:54 'ar_model_epoch=17-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:54 'ar_model_epoch=01-val_loss=0.04-v1.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 'ar_model_epoch=18-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 'ar_model_epoch=02-val_loss=0.04.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 'ar_model_epoch=19-val_loss=0.01.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 'ar_model_epoch=03-val_loss=0.03.tlt'\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 'ar_model_epoch=04-val_loss=0.04.tlt'\n"
     ]
    }
   ],
   "source": [
    "print('Encrypted checkpoints:')\n",
    "print('---------------------')\n",
    "!ls -ltrh $HOST_RESULTS_DIR/rgb_3d_ptm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rename a model: Note that the training is not deterministic, so you may change the model name accordingly.\n",
      "---------------------\n",
      "-rw-r--r-- 1 jupyter jupyter 317M May 11 22:55 /home/jupyter/action_recognition_net/results/rgb_3d_ptm/rgb_only_model.tlt\n"
     ]
    }
   ],
   "source": [
    "print('Rename a model: Note that the training is not deterministic, so you may change the model name accordingly.')\n",
    "print('---------------------')\n",
    "# NOTE: The following command may require `sudo`. You can run the command outside the notebook.\n",
    "!mv $HOST_RESULTS_DIR/rgb_3d_ptm/ar_model_epoch=19-val_loss=0.01.tlt $HOST_RESULTS_DIR/rgb_3d_ptm/rgb_only_model.tlt \n",
    "!ls -ltrh $HOST_RESULTS_DIR/rgb_3d_ptm/rgb_only_model.tlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `OPTIONAL` 4.2 Train 2D model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Important Note` The following cells are using SHAD dataset. \n",
    "\n",
    "Firstly, we will train a 2D RGB-only model from scratch\n",
    "\n",
    "\n",
    "**MAKE SURE TO UPDATE PATHS IN SPECS FILES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(\"Train RGB only model from scratch\")\n",
    "# !action_recognition train \\\n",
    "#                   -e $HOST_SPECS_DIR/train_rgb_2d.yaml \\\n",
    "#                   -r $HOST_RESULTS_DIR/rgb_2d \\\n",
    "#                   -k $KEY \\\n",
    "#                   dataset_config.train_dataset_dir=$HOST_DATA_DIR/train \\\n",
    "#                   dataset_config.val_dataset_dir=$HOST_DATA_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"To resume training from a checkpoint, set the resume_training_checkpoint_path option to be the .tlt you want to resume from\")\n",
    "# print(\"remember to remove the `=` in the checkpoint's file name\")\n",
    "# !action_recognition train \\\n",
    "#                   -e $HOST_SPECS_DIR/train_rgb_2d.yaml \\\n",
    "#                   -r $HOST_RESULTS_DIR/rgb_2d \\\n",
    "#                   -k $KEY \\\n",
    "#                   resume_training_checkpoint_path="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Encrypted checkpoints:')\n",
    "# print('---------------------')\n",
    "# !ls -ltrh $HOST_RESULTS_DIR/rgb_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Rename a model: ')\n",
    "# print('---------------------')\n",
    "# !echo <passwd> | sudo -S mv $HOST_RESULTS_DIR/rgb_2d/ar_model_epoch=21-val_loss=0.88.tlt $HOST_RESULTS_DIR/rgb_2d/rgb_only_model.tlt \n",
    "# !ls -ltrh $HOST_RESULTS_DIR/rgb_2d/rgb_only_model.tlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will train a 2D optical flow only model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train optical flow only model from scratch\")\n",
    "# !action_recognition train \\\n",
    "#                   -e $HOST_SPECS_DIR/train_of_2d.yaml \\\n",
    "#                   -r $HOST_RESULTS_DIR/of_2d \\\n",
    "#                   -k $KEY \\\n",
    "#                   dataset_config.train_dataset_dir=$HOST_DATA_DIR/train \\\n",
    "#                   dataset_config.val_dataset_dir=$HOST_DATA_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Encrypted checkpoints:')\n",
    "# print('---------------------')\n",
    "# !ls -ltrh $HOST_RESULTS_DIR/of_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Rename a model: ')\n",
    "# print('---------------------')\n",
    "# !echo <passwd> | sudo -S mv $HOST_RESULTS_DIR/of_2d/ar_model_epoch=29-val_loss=0.94.tlt $HOST_RESULTS_DIR/of_2d/of_only_model.tlt \n",
    "# !ls -ltrh $HOST_RESULTS_DIR/of_2d/of_only_model.tlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will train a 2D joint model which consumed both RGB frames and optical flow frames based on two pretrained single stream model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train joint model based on RGB and OF model\")\n",
    "# !action_recognition train \\\n",
    "#                   -e $HOST_SPECS_DIR/train_joint_2d.yaml \\\n",
    "#                   -r $HOST_RESULTS_DIR/joint_2d \\\n",
    "#                   -k $KEY \\\n",
    "#                   model_config.rgb_pretrained_model_path=$HOST_RESULTS_DIR/rgb_2d/rgb_only_model.tlt \\\n",
    "#                   model_config.of_pretrained_model_path=$HOST_RESULTS_DIR/of_2d/of_only_model.tlt \\\n",
    "#                   dataset_config.train_dataset_dir=$HOST_DATA_DIR/train \\\n",
    "#                   dataset_config.val_dataset_dir=$HOST_DATA_DIR/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Encrypted checkpoints:')\n",
    "# print('---------------------')\n",
    "# !ls -ltrh $HOST_RESULTS_DIR/joint_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Rename a model: ')\n",
    "# print('---------------------')\n",
    "# !echo <passwd> | sudo -S mv $HOST_RESULTS_DIR/joint_2d/ar_model_epoch=16-val_loss=0.60.tlt $HOST_RESULTS_DIR/joint_2d/joint_model.tlt \n",
    "# !ls -ltrh $HOST_RESULTS_DIR/joint_2d/joint_model.tlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluate trained models <a class=\"anchor\" id=\"head-4\"></a>\n",
    "\n",
    "We provide two different sample strategy to evaluate the pretrained model on video clips.\n",
    "\n",
    "* `center` mode: pick up the middle frames of a sequence to do inference. For example, if the model requires 32 frames as input and a video clip has 128 frames, then we will choose the frames from index 48 to index 79 to do the inference. \n",
    "* `conv` mode: convolutionly sample 10 sequences out of a single video and do inference. The final results are averaged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate RGB model trained with PTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/scripts/evaluate.py:154: UserWarning: \n",
      "'evaluate_rgb.yaml' is validated against ConfigStore schema with the same name.\n",
      "This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "ResNet3d(\n",
      "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=2, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc_cls): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "/opt/conda/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "100%|███████████████████████████████████████████| 60/60 [00:02<00:00, 27.85it/s]\n",
      "*******************************\n",
      "fall_floor    100.0\n",
      "ride_bike     100.0\n",
      "*******************************\n",
      "Total accuracy: 100.0\n",
      "Average class accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "!action_recognition evaluate \\\n",
    "                    -e $HOST_SPECS_DIR/evaluate_rgb.yaml \\\n",
    "                    -k $KEY \\\n",
    "                    model=$HOST_RESULTS_DIR/rgb_3d_ptm/rgb_only_model.tlt  \\\n",
    "                    batch_size=1 \\\n",
    "                    test_dataset_dir=$HOST_DATA_DIR/test \\\n",
    "                    video_eval_mode=center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Inferences <a class=\"anchor\" id=\"head-5\"></a>\n",
    "In this section, we run the action recognition inference tool to generate inferences with the trained RGB models and print the results. \n",
    "\n",
    "There are also two modes for inference just like evaluation: `center` mode and `conv` mode. And the final output will show each input sequence label in the videos like:\n",
    "`[video_sample_path] [labels list for sequences in the video sample]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-11 23:02:41 nemo_logging:349] /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/scripts/inference.py:88: UserWarning: \n",
      "    'infer_rgb.yaml' is validated against ConfigStore schema with the same name.\n",
      "    This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "    \n",
      "ResNet3d(\n",
      "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=2, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc_cls): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "[NeMo W 2022-05-11 23:02:43 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "      stream(template_mgs % msg_args)\n",
      "    \n",
      "100%|███████████████████████████████████████████| 30/30 [00:01<00:00, 15.89it/s]\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_4 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_1 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_le_med_2 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_11 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_5 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_ri_med_1 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/lady_on_bike_ride_bike_f_cm_np1_ri_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_fr_med_3 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_bad_2 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_2 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_1 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/lady_on_bike_ride_bike_f_cm_np1_ba_med_1 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ri_med_10 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_9 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_fr_med_3 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_1 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_8 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_3 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ba_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_7 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_fr_med_6 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_ba_med_4 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Learn_How_To_Ride_A_Bike_at_Any_Age_ride_bike_f_cm_np1_le_med_5 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Yorki_Kassy_beim_Fahrrad_fahren_ride_bike_f_cm_np1_le_med_2 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Schuodde_kann_kein_Fahrrad_fahren_ride_bike_l_cm_np1_le_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Fahrrad_fahren_mit_Albert_ride_bike_f_cm_np1_ba_med_0 : ['ride_bike']\n",
      "/home/jupyter/action_recognition_net/data/test/ride_bike/Tour_de_France_2009_ETAPA_16_ESPN_ESP__Kilometros_finales_ride_bike_f_cm_np1_ri_bad_1 : ['ride_bike']\n"
     ]
    }
   ],
   "source": [
    "!action_recognition inference \\\n",
    "                    -e $HOST_SPECS_DIR/infer_rgb.yaml \\\n",
    "                    -k $KEY \\\n",
    "                    model=$HOST_RESULTS_DIR/rgb_3d_ptm/rgb_only_model.tlt \\\n",
    "                    inference_dataset_dir=$HOST_DATA_DIR/test/ride_bike \\\n",
    "                    video_inf_mode=center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Deploy! <a class=\"anchor\" id=\"head-6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $HOST_RESULTS_DIR/export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-05-11 23:04:56 nemo_logging:349] /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/scripts/export.py:155: UserWarning: \n",
      "    'export_rgb.yaml' is validated against ConfigStore schema with the same name.\n",
      "    This behavior is deprecated in Hydra 1.1 and will be removed in Hydra 1.2.\n",
      "    See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/automatic_schema_matching for migration instructions.\n",
      "    \n",
      "ResNet3d(\n",
      "  (conv1): Conv3d(3, 64, kernel_size=(5, 7, 7), stride=(2, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "  (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool3d(kernel_size=(1, 3, 3), stride=2, padding=(0, 1, 1), dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock3d(\n",
      "      (conv1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "        (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock3d(\n",
      "      (conv1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "      (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avg_pool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "  (fc_cls): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n",
      "[NeMo W 2022-05-11 23:04:59 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "      stream(template_mgs % msg_args)\n",
      "    \n",
      "graph(%input_rgb : Float(*, 3, 3, 224, 224, strides=[451584, 150528, 50176, 224, 1], requires_grad=0, device=cuda:0),\n",
      "      %fc_cls.weight : Float(2, 512, strides=[512, 1], requires_grad=1, device=cuda:0),\n",
      "      %fc_cls.bias : Float(2, strides=[1], requires_grad=1, device=cuda:0),\n",
      "      %200 : Float(64, 3, 5, 7, 7, strides=[735, 245, 49, 7, 1], requires_grad=0, device=cuda:0),\n",
      "      %201 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %203 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %204 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %206 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %207 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %209 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %210 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %212 : Float(64, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %213 : Float(64, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %215 : Float(128, 64, 3, 3, 3, strides=[1728, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %216 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %218 : Float(128, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %219 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %221 : Float(128, 64, 1, 1, 1, strides=[64, 1, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %222 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %224 : Float(128, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %225 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %227 : Float(128, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %228 : Float(128, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %230 : Float(256, 128, 3, 3, 3, strides=[3456, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %231 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %233 : Float(256, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %234 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %236 : Float(256, 128, 1, 1, 1, strides=[128, 1, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %237 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %239 : Float(256, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %240 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %242 : Float(256, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %243 : Float(256, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %245 : Float(512, 256, 3, 3, 3, strides=[6912, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %246 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %248 : Float(512, 512, 3, 3, 3, strides=[13824, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %249 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %251 : Float(512, 256, 1, 1, 1, strides=[256, 1, 1, 1, 1], requires_grad=0, device=cuda:0),\n",
      "      %252 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %254 : Float(512, 512, 3, 3, 3, strides=[13824, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %255 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %257 : Float(512, 512, 3, 3, 3, strides=[13824, 27, 9, 3, 1], requires_grad=0, device=cuda:0),\n",
      "      %258 : Float(512, strides=[1], requires_grad=0, device=cuda:0),\n",
      "      %259 : Long(1, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %199 : Float(*, 64, 2, 112, 112, strides=[1605632, 25088, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[5, 7, 7], pads=[2, 3, 3, 2, 3, 3], strides=[2, 2, 2]](%input_rgb, %200, %201)\n",
      "  %125 : Float(*, 64, 2, 112, 112, strides=[1605632, 25088, 12544, 112, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%199) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %126 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::MaxPool[kernel_shape=[1, 3, 3], pads=[0, 1, 1, 0, 1, 1], strides=[2, 2, 2]](%125)\n",
      "  %202 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%126, %203, %204)\n",
      "  %129 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%202) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %205 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%129, %206, %207)\n",
      "  %132 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Add(%205, %126) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %133 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%132)\n",
      "  %208 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%133, %209, %210)\n",
      "  %136 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%208) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %211 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%136, %212, %213)\n",
      "  %139 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Add(%211, %133) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %140 : Float(*, 64, 1, 56, 56, strides=[200704, 3136, 3136, 56, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%139) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %214 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 2, 2]](%140, %215, %216)\n",
      "  %143 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%214) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %217 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%143, %218, %219)\n",
      "  %220 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[1, 1, 1], pads=[0, 0, 0, 0, 0, 0], strides=[1, 2, 2]](%140, %221, %222)\n",
      "  %148 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Add(%217, %220) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %149 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%148)\n",
      "  %223 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%149, %224, %225)\n",
      "  %152 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%223) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %226 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%152, %227, %228)\n",
      "  %155 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Add(%226, %149) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %156 : Float(*, 128, 1, 28, 28, strides=[100352, 784, 784, 28, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%155) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %229 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 2, 2]](%156, %230, %231)\n",
      "  %159 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%229) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %232 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%159, %233, %234)\n",
      "  %235 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[1, 1, 1], pads=[0, 0, 0, 0, 0, 0], strides=[1, 2, 2]](%156, %236, %237)\n",
      "  %164 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%232, %235) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %165 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%164)\n",
      "  %238 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%165, %239, %240)\n",
      "  %168 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%238) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %241 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%168, %242, %243)\n",
      "  %171 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Add(%241, %165) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %172 : Float(*, 256, 1, 14, 14, strides=[50176, 196, 196, 14, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%171) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %244 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 2, 2]](%172, %245, %246)\n",
      "  %175 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%244) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %247 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%175, %248, %249)\n",
      "  %250 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[1, 1, 1], pads=[0, 0, 0, 0, 0, 0], strides=[1, 2, 2]](%172, %251, %252)\n",
      "  %180 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%247, %250) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %181 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%180)\n",
      "  %253 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%181, %254, %255)\n",
      "  %184 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%253) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %256 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Conv[dilations=[1, 1, 1], group=1, kernel_shape=[3, 3, 3], pads=[1, 1, 1, 1, 1, 1], strides=[1, 1, 1]](%184, %257, %258)\n",
      "  %187 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Add(%256, %181) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:70:0\n",
      "  %188 : Float(*, 512, 1, 7, 7, strides=[25088, 49, 49, 7, 1], requires_grad=1, device=cuda:0) = onnx::Relu(%187) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1296:0\n",
      "  %189 : Float(*, 512, 1, 1, 1, strides=[512, 1, 1, 1, 1], requires_grad=1, device=cuda:0) = onnx::GlobalAveragePool(%188) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1147:0\n",
      "  %190 : Long(5, strides=[1], device=cpu) = onnx::Shape(%189)\n",
      "  %191 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
      "  %192 : Long(device=cpu) = onnx::Gather[axis=0](%190, %191) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:246:0\n",
      "  %194 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%192)\n",
      "  %196 : Long(2, strides=[1], device=cpu) = onnx::Concat[axis=0](%194, %259)\n",
      "  %197 : Float(*, *, strides=[512, 1], requires_grad=1, device=cuda:0) = onnx::Reshape(%189, %196) # /home/jenkins/agent/workspace/tlt-pytorch-main-nightly/cv/action_recognition/model/resnet3d.py:246:0\n",
      "  %fc_pred : Float(*, 2, strides=[2, 1], requires_grad=1, device=cuda:0) = onnx::Gemm[alpha=1., beta=1., transB=1](%197, %fc_cls.weight, %fc_cls.bias) # /opt/conda/lib/python3.8/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%fc_pred)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export the RGB model to encrypted ONNX model\n",
    "!action_recognition export \\\n",
    "                   -e $HOST_SPECS_DIR/export_rgb.yaml \\\n",
    "                   -k $KEY \\\n",
    "                   model=$HOST_RESULTS_DIR/rgb_3d_ptm/rgb_only_model.tlt\\\n",
    "                   output_file=$HOST_RESULTS_DIR/export/rgb_resnet18_3.etlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model:\n",
      "------------\n",
      "total 127M\n",
      "-rw-r--r-- 1 jupyter jupyter 127M May 11 23:05 rgb_resnet18_3.etlt\n"
     ]
    }
   ],
   "source": [
    "print('Exported model:')\n",
    "print('------------')\n",
    "!ls -lth $HOST_RESULTS_DIR/export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook has come to an end. You may continue by deploying this model to [DeepStream](https://docs.nvidia.com/metropolis/deepstream/dev-guide/text/DS_3D_Action.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [tao-toolkit-pyt] [conda env:root] * (Local)",
   "language": "python",
   "name": "local-conda-root-nvcr.io_nvidia_tao_tao-toolkit-pyt_v3.21.11-py3__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
